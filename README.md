# TesisMDP Supervisado - Sistema de Clasificaci√≥n Binaria

Sistema completo para entrenamiento y validaci√≥n de modelos de clasificaci√≥n binaria (normal/fallas) utilizando m√∫ltiples arquitecturas de deep learning. El sistema incluye 25 modelos diferentes organizados en 5 grupos principales, cada uno con m√∫ltiples variantes para comparaci√≥n.

---

## üìã Tabla de Contenidos

1. [Descripci√≥n General](#descripci√≥n-general)
2. [Estructura del Proyecto](#estructura-del-proyecto)
3. [Requisitos e Instalaci√≥n](#requisitos-e-instalaci√≥n)
4. [Configuraci√≥n](#configuraci√≥n)
5. [Estructura del Dataset](#estructura-del-dataset)
6. [Procesamiento de Im√°genes](#procesamiento-de-im√°genes)
7. [Modelos Disponibles](#modelos-disponibles)
8. [Uso del Sistema](#uso-del-sistema)
9. [Validaci√≥n de Modelos](#validaci√≥n-de-modelos)
10. [Caracter√≠sticas Implementadas](#caracter√≠sticas-implementadas)
11. [Par√°metros y Opciones](#par√°metros-y-opciones)
12. [Archivos Generados](#archivos-generados)
13. [Ejemplos de Uso](#ejemplos-de-uso)

---

## üéØ Descripci√≥n General

Este proyecto implementa un sistema completo de entrenamiento supervisado para clasificaci√≥n binaria de im√°genes. El sistema est√° dise√±ado para:

- **Entrenar m√∫ltiples arquitecturas** de forma autom√°tica y comparativa
- **Procesar im√°genes en parches** de 224x224 sin reescalar las im√°genes originales
- **Implementar early stopping** autom√°tico para evitar sobreentrenamiento
- **Generar m√©tricas completas** y matrices de confusi√≥n
- **Validar modelos entrenados** en datasets de prueba

**Total de modelos entrenables: 25 variantes** distribuidas en 5 grupos principales.

---

## üìÅ Estructura del Proyecto

```
TesisMDP_supervised/
‚îú‚îÄ‚îÄ config.py                          # Configuraci√≥n centralizada
‚îú‚îÄ‚îÄ dataset_supervisado.py             # Dataset con divisi√≥n en parches
‚îú‚îÄ‚îÄ train_all_models.py                # Script principal para entrenar todos los modelos
‚îú‚îÄ‚îÄ validate_model.py                  # Script para validar modelos entrenados
‚îú‚îÄ‚îÄ requirements.txt                   # Dependencias del proyecto
‚îÇ
‚îú‚îÄ‚îÄ modelos/
‚îÇ   ‚îú‚îÄ‚îÄ modelo1_autoencoder/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train_supervised.py        # Entrenamiento modelo 1
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model_classifier.py        # Clasificadores originales
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ autoencoder_models.py      # 5 variantes de autoencoders
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/                    # Modelos entrenados guardados aqu√≠
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ outputs/                   # Resultados y m√©tricas
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ modelo2_features/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train_supervised.py        # Entrenamiento modelo 2
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/                    # Modelos entrenados
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ outputs/                   # Resultados
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ modelo3_transformer/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train_supervised.py        # Entrenamiento modelo 3 (ViT)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/                    # Modelos entrenados
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ outputs/                   # Resultados
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ modelo4_fastflow/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train_supervised.py        # Entrenamiento modelo 4
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/                    # Modelos entrenados
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ outputs/                   # Resultados
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ modelo5_stpm/
‚îÇ       ‚îú‚îÄ‚îÄ train_supervised.py        # Entrenamiento modelo 5
‚îÇ       ‚îú‚îÄ‚îÄ models/                    # Modelos entrenados
‚îÇ       ‚îî‚îÄ‚îÄ outputs/                   # Resultados
‚îÇ
‚îú‚îÄ‚îÄ preprocesamiento/
‚îÇ   ‚îú‚îÄ‚îÄ preprocesamiento.py            # Funciones de preprocesamiento
‚îÇ   ‚îî‚îÄ‚îÄ correct_board.py               # Correcci√≥n de tableros
‚îÇ
‚îî‚îÄ‚îÄ outputs/                           # Resultados globales de validaci√≥n
```

---

## üîß Requisitos e Instalaci√≥n

### Requisitos del Sistema

- **Python**: 3.8 o superior
- **CUDA**: Recomendado para entrenamiento (GPU NVIDIA compatible)
- **RAM**: M√≠nimo 8GB (recomendado 16GB+)
- **Espacio en disco**: Depende del tama√±o del dataset

### Instalaci√≥n de Dependencias

```bash
# Instalar todas las dependencias
pip install -r requirements.txt
```

### Dependencias Principales

- **PyTorch** >= 1.9.0 (con soporte CUDA recomendado)
- **Torchvision** >= 0.10.0
- **OpenCV** >= 4.5.0
- **scikit-learn** >= 1.0.0
- **matplotlib** >= 3.5.0
- **seaborn** >= 0.11.0
- **tensorboard** >= 2.8.0

---

## ‚öôÔ∏è Configuraci√≥n

### 1. Configurar Ruta del Dataset

Edita el archivo `config.py` y actualiza la ruta a tu dataset:

```python
DATASET_SUPERVISADO_PATH = r"E:\Dataset\Validacion_procesadas"  # Cambiar esta ruta
```

**Importante**: El dataset debe contener dos subcarpetas:
- `normal/` - Im√°genes sin fallas (label=0)
- `fallas/` - Im√°genes con fallas (label=1)

---

## üìÇ Estructura del Dataset

El dataset debe tener la siguiente estructura:

```
dataset_supervisado/
‚îú‚îÄ‚îÄ normal/
‚îÇ   ‚îú‚îÄ‚îÄ imagen1.png
‚îÇ   ‚îú‚îÄ‚îÄ imagen2.png
‚îÇ   ‚îú‚îÄ‚îÄ imagen3.jpg
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ fallas/
    ‚îú‚îÄ‚îÄ imagen1.png
    ‚îú‚îÄ‚îÄ imagen2.png
    ‚îú‚îÄ‚îÄ imagen3.jpg
    ‚îî‚îÄ‚îÄ ...
```

### Formatos Soportados

- PNG (.png)
- JPEG (.jpg, .jpeg)
- BMP (.bmp)
- TIFF (.tif, .tiff)

---

## üñºÔ∏è Procesamiento de Im√°genes

### Caracter√≠sticas del Procesamiento

1. **Divisi√≥n en Parches**: Las im√°genes se dividen en parches de **224x224 p√≠xeles** sin reescalar la imagen original
2. **Sin Preprocesamiento**: Las im√°genes se usan directamente
3. **Conversi√≥n de Canales**:
   - Im√°genes a color (3 canales): Se convierten de BGR a RGB
   - Im√°genes en escala de grises (1 canal): Se replica a 3 canales (R=G=B)
4. **Normalizaci√≥n**: Las im√°genes se normalizan a [0, 1] antes de pasarlas al modelo

### Divisi√≥n en Parches

- **Tama√±o de parche**: 224x224 p√≠xeles (por defecto)
- **Sin reescalado**: La imagen original mantiene su tama√±o
- **Extracci√≥n**: Se extrae el primer parche de cada imagen (se puede extender para usar todos los parches)

---

## ü§ñ Modelos Disponibles

El sistema incluye **25 modelos diferentes** organizados en 5 grupos:

### **Modelo 1: Autoencoders** (5 variantes)

Basado en diferentes arquitecturas de autoencoders como encoder para el clasificador:

1. **ConvAE** (Convolutional Autoencoder)
   - Arquitectura convolucional b√°sica
   - Feature dimensions: 64
   - Archivo: `classifier_convae.pt`

2. **U-Net Autoencoder**
   - Encoder basado en arquitectura U-Net
   - Feature dimensions: 64
   - Archivo: `classifier_unet.pt`

3. **VAE** (Variational Autoencoder)
   - Encoder variacional con espacio latente estoc√°stico
   - Feature dimensions: 64
   - Archivo: `classifier_vae.pt`

4. **Denoising Autoencoder**
   - Encoder con regularizaci√≥n (BatchNorm y Dropout)
   - Feature dimensions: 64
   - Archivo: `classifier_denoising.pt`

5. **ResNet-18 Autoencoder**
   - Encoder basado en ResNet-18 preentrenado
   - Feature dimensions: 512
   - Archivo: `classifier_resnet18.pt`

---

### **Modelo 2: Backbones** (5 variantes)

Clasificador basado en diferentes backbones preentrenados:

1. **ResNet18**
   - Feature dimensions: 512
   - Archivo: `modelo2_resnet18.pt`

2. **WideResNet50-2**
   - Feature dimensions: 2048
   - Archivo: `modelo2_wide_resnet50_2.pt`

3. **EfficientNet-B0**
   - Feature dimensions: 1280
   - Archivo: `modelo2_efficientnet_b0.pt`

4. **VGG16**
   - Feature dimensions: 512
   - Archivo: `modelo2_vgg16.pt`

5. **DenseNet121**
   - Feature dimensions: 1024
   - Archivo: `modelo2_densenet121.pt`

---

### **Modelo 3: Vision Transformer (ViT)** (5 variantes)

Clasificador basado en Vision Transformers con diferentes configuraciones:

1. **ViT-B/16** (Base, patch size 16)
   - Feature dimensions: 768
   - Archivo: `modelo3_vit_b_16.pt`

2. **ViT-B/32** (Base, patch size 32)
   - Feature dimensions: 768
   - Archivo: `modelo3_vit_b_32.pt`

3. **ViT-L/16** (Large, patch size 16)
   - Feature dimensions: 1024
   - Archivo: `modelo3_vit_l_16.pt`

4. **ViT-L/32** (Large, patch size 32)
   - Feature dimensions: 1024
   - Archivo: `modelo3_vit_l_32.pt`

5. **ViT-H/14** (Huge, patch size 14)
   - Feature dimensions: 1280
   - Archivo: `modelo3_vit_h_14.pt`

**Clasificador del Modelo 3**: MLP de 3 capas (feature_dims ‚Üí 512 ‚Üí 256 ‚Üí 2) con ReLU y Dropout(0.5)

---

### **Modelo 4: Backbones** (5 variantes)

Clasificador basado en diferentes backbones preentrenados:

1. **ResNet18**
   - Feature dimensions: 512
   - Archivo: `modelo4_resnet18.pt`

2. **WideResNet50-2**
   - Feature dimensions: 2048
   - Archivo: `modelo4_wide_resnet50_2.pt`

3. **EfficientNet-B0**
   - Feature dimensions: 1280
   - Archivo: `modelo4_efficientnet_b0.pt`

4. **VGG16**
   - Feature dimensions: 512
   - Archivo: `modelo4_vgg16.pt`

5. **DenseNet121**
   - Feature dimensions: 1024
   - Archivo: `modelo4_densenet121.pt`

---

### **Modelo 5: Backbones** (5 variantes)

Clasificador basado en diferentes backbones preentrenados:

1. **ResNet18**
   - Feature dimensions: 512
   - Archivo: `modelo5_resnet18.pt`

2. **WideResNet50-2**
   - Feature dimensions: 2048
   - Archivo: `modelo5_wide_resnet50_2.pt`

3. **EfficientNet-B0**
   - Feature dimensions: 1280
   - Archivo: `modelo5_efficientnet_b0.pt`

4. **VGG16**
   - Feature dimensions: 512
   - Archivo: `modelo5_vgg16.pt`

5. **DenseNet121**
   - Feature dimensions: 1024
   - Archivo: `modelo5_densenet121.pt`

---

## üöÄ Uso del Sistema

### Entrenamiento de Modelos

#### Entrenar un Modelo Espec√≠fico

```bash
# Entrenar Modelo 1 (entrena autom√°ticamente las 5 variantes de autoencoders)
python train_all_models.py --modelo 1

# Entrenar Modelo 2 (entrena autom√°ticamente las 5 variantes de backbones)
python train_all_models.py --modelo 2

# Entrenar Modelo 3 (entrena autom√°ticamente las 5 variantes de ViT)
python train_all_models.py --modelo 3

# Entrenar Modelo 4 (entrena autom√°ticamente las 5 variantes de backbones)
python train_all_models.py --modelo 4

# Entrenar Modelo 5 (entrena autom√°ticamente las 5 variantes de backbones)
python train_all_models.py --modelo 5
```

#### Entrenar Todos los Modelos

```bash
# Entrenar todos los modelos (25 variantes en total)
python train_all_models.py --modelo all
```

#### Ejemplos con Par√°metros Personalizados

```bash
# Entrenar con par√°metros personalizados
python train_all_models.py --modelo 1 \
    --epochs 100 \
    --lr 0.0001 \
    --batch_size 64 \
    --img_size 224

# Entrenar sin early stopping
python train_all_models.py --modelo 2 --no-early_stopping

# Entrenar con patience personalizado
python train_all_models.py --modelo 3 --patience 15 --min_delta 0.0005
```

---

## ‚úÖ Validaci√≥n de Modelos

### Script de Validaci√≥n

El script `validate_model.py` permite validar cualquier modelo entrenado en un dataset de validaci√≥n.

#### Uso B√°sico

```bash
# Validar modelo 1 (ConvAE)
python validate_model.py \
    --modelo 1 \
    --model_path modelos/modelo1_autoencoder/models/classifier_convae.pt \
    --val_path ruta/al/dataset/validacion \
    --encoder_type convae

# Validar modelo 2 (ResNet18)
python validate_model.py \
    --modelo 2 \
    --model_path modelos/modelo2_features/models/modelo2_resnet18.pt \
    --val_path ruta/al/dataset/validacion \
    --backbone resnet18

# Validar modelo 3 (ViT-B/16)
python validate_model.py \
    --modelo 3 \
    --model_path modelos/modelo3_transformer/models/modelo3_vit_b_16.pt \
    --val_path ruta/al/dataset/validacion \
    --model_name vit_b_16
```

#### Estructura del Dataset de Validaci√≥n

El dataset de validaci√≥n debe tener la misma estructura que el de entrenamiento:

```
ruta/al/dataset/validacion/
‚îú‚îÄ‚îÄ normal/
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ fallas/
    ‚îî‚îÄ‚îÄ ...
```

### Salidas de la Validaci√≥n

El script genera:

1. **M√©tricas en consola**:
   - Loss
   - Accuracy
   - Precision
   - Recall
   - F1-Score
   - Matriz de confusi√≥n
   - Reporte de clasificaci√≥n

2. **Archivo JSON** (`outputs/validation_results_modeloX_TIMESTAMP.json`):
   - Todas las m√©tricas en formato JSON
   - Configuraci√≥n usada
   - Timestamp

3. **Gr√°fica de Matriz de Confusi√≥n** (`outputs/confusion_matrix_modeloX_TIMESTAMP.png`):
   - Visualizaci√≥n de la matriz de confusi√≥n

---

## üéõÔ∏è Caracter√≠sticas Implementadas

### 1. Early Stopping Autom√°tico

- **Activado por defecto** en todos los modelos
- **Par√°metros por defecto**:
  - `patience`: 10 √©pocas
  - `min_delta`: 0.001 (para modelo 1 y 3) / 0.0001 (para modelo 4)
- **Detenci√≥n autom√°tica** si la loss de validaci√≥n < 0.001
- Se puede desactivar con `--no-early_stopping`

### 2. Divisi√≥n en Parches

- **Tama√±o de parche**: 224x224 p√≠xeles (por defecto)
- **Sin reescalado**: Las im√°genes originales no se reescalan
- **Extracci√≥n**: Se divide la imagen en parches y se usa el primer parche

### 3. Batch Size Autom√°tico

El sistema calcula autom√°ticamente el batch size √≥ptimo seg√∫n la memoria GPU disponible:

- **GPU >= 24GB**: Batch sizes grandes (64-128)
- **GPU >= 12GB**: Batch sizes medianos (32-64)
- **GPU >= 8GB**: Batch sizes peque√±os (16-32)
- **GPU < 8GB**: Batch sizes m√≠nimos (4-16)

### 4. Split Autom√°tico de Datos

- **85%** para entrenamiento
- **15%** para validaci√≥n
- **Proporci√≥n de clases mantenida** en ambos splits

### 5. Logging con TensorBoard

- M√©tricas guardadas autom√°ticamente en `runs/`
- Incluye: Loss, Accuracy, Precision, Recall, F1-Score, Learning Rate

---

## üìä Par√°metros y Opciones

### Par√°metros Globales

| Par√°metro | Tipo | Default | Descripci√≥n |
|-----------|------|---------|-------------|
| `--modelo` | str | - | Modelo a entrenar: `1`, `2`, `3`, `4`, `5`, `all` |
| `--data_dir` | str | None | Directorio con carpetas normal/fallas (usa config.py si no se especifica) |
| `--img_size` | int | 224 | Tama√±o de los parches (224x224) |
| `--batch_size` | int | None | Tama√±o de batch (se calcula autom√°ticamente si no se especifica) |
| `--epochs` | int | 50 | N√∫mero de √©pocas |
| `--lr` | float | 1e-3 | Learning rate |
| `--early_stopping` | flag | True | Activar early stopping (por defecto activado) |
| `--no-early_stopping` | flag | - | Desactivar early stopping |
| `--patience` | int | 10 | Paciencia para early stopping (√©pocas sin mejora) |
| `--min_delta` | float | 0.001 | Mejora m√≠nima para considerar mejora |
| `--forzar_cpu` | flag | False | Forzar uso de CPU (no recomendado) |

### Par√°metros Espec√≠ficos por Modelo

#### Modelo 1
- `--encoder_type`: Tipo de autoencoder (`convae`, `unet`, `vae`, `denoising`, `resnet18`)

#### Modelo 2, 4, 5
- `--backbone`: Backbone a usar (se entrenan todas las variantes autom√°ticamente)

#### Modelo 3
- `--model_name`: Modelo ViT (`vit_b_16`, `vit_b_32`, `vit_l_16`, `vit_l_32`, `vit_h_14`)

---

## üìÅ Archivos Generados

### Durante el Entrenamiento

Cada modelo genera:

1. **Modelo entrenado** (`.pt`):
   - Guardado en `modelos/modeloX/models/`
   - Nombre seg√∫n la variante entrenada

2. **Historial de entrenamiento** (`.json`):
   - Guardado en `modelos/modeloX/models/`
   - Contiene: loss, accuracy, precision, recall, f1 por √©poca
   - Configuraci√≥n usada

3. **Logs de TensorBoard**:
   - Guardados en `runs/`
   - Visualizables con: `tensorboard --logdir runs`

### Durante la Validaci√≥n

1. **Resultados JSON** (`outputs/validation_results_modeloX_TIMESTAMP.json`)
2. **Matriz de confusi√≥n** (`outputs/confusion_matrix_modeloX_TIMESTAMP.png`)

---

## üí° Ejemplos de Uso

### Ejemplo 1: Entrenar Todos los Modelos

```bash
# Entrenar todos los modelos con configuraci√≥n por defecto
python train_all_models.py --modelo all
```

Esto entrenar√°:
- Modelo 1: 5 variantes de autoencoders
- Modelo 2: 5 variantes de backbones
- Modelo 3: 5 variantes de ViT
- Modelo 4: 5 variantes de backbones
- Modelo 5: 5 variantes de backbones

**Total: 25 modelos**

### Ejemplo 2: Entrenar Solo Modelo 1 con Configuraci√≥n Personalizada

```bash
python train_all_models.py --modelo 1 \
    --epochs 100 \
    --lr 0.0001 \
    --batch_size 32 \
    --patience 15
```

### Ejemplo 3: Validar un Modelo Espec√≠fico

```bash
# Validar ViT-B/16
python validate_model.py \
    --modelo 3 \
    --model_path modelos/modelo3_transformer/models/modelo3_vit_b_16.pt \
    --val_path E:\Dataset\Validacion_procesadas \
    --model_name vit_b_16 \
    --batch_size 32
```

### Ejemplo 4: Entrenar sin Early Stopping

```bash
python train_all_models.py --modelo 2 --no-early_stopping --epochs 100
```

### Ejemplo 5: Entrenar con Tama√±o de Parche Personalizado

```bash
python train_all_models.py --modelo 1 --img_size 256
```

---

## üîç Resumen de Modelos por Grupo

| Grupo | Variantes | Arquitecturas |
|-------|-----------|---------------|
| **Modelo 1** | 5 | ConvAE, U-Net, VAE, Denoising, ResNet-18 AE |
| **Modelo 2** | 5 | ResNet18, WideResNet50-2, EfficientNet-B0, VGG16, DenseNet121 |
| **Modelo 3** | 5 | ViT-B/16, ViT-B/32, ViT-L/16, ViT-L/32, ViT-H/14 |
| **Modelo 4** | 5 | ResNet18, WideResNet50-2, EfficientNet-B0, VGG16, DenseNet121 |
| **Modelo 5** | 5 | ResNet18, WideResNet50-2, EfficientNet-B0, VGG16, DenseNet121 |
| **TOTAL** | **25** | - |

---

## üìù Notas Importantes

1. **GPU Recomendada**: El entrenamiento es mucho m√°s r√°pido con GPU. El sistema detecta autom√°ticamente la GPU disponible.

2. **Memoria**: Los modelos m√°s grandes (ViT-H/14, WideResNet50-2) requieren m√°s memoria GPU.

3. **Tiempo de Entrenamiento**: Entrenar todos los modelos puede tomar varias horas dependiendo del hardware y tama√±o del dataset.

4. **Early Stopping**: Est√° activado por defecto para evitar sobreentrenamiento y ahorrar tiempo.

5. **Parches**: El sistema divide las im√°genes en parches de 224x224. Si una imagen es m√°s peque√±a que 224x224, se reescalar√° autom√°ticamente.

---

## üêõ Soluci√≥n de Problemas

### Error: "CUDA no est√° disponible"
- Verifica que tengas una GPU NVIDIA compatible
- Instala PyTorch con soporte CUDA: `pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118`

### Error: "No se encuentra el dataset"
- Verifica la ruta en `config.py`
- Aseg√∫rate de que existan las carpetas `normal/` y `fallas/`

### Error: "Out of Memory"
- Reduce el `batch_size` manualmente
- Usa modelos m√°s peque√±os (ResNet18 en lugar de WideResNet50-2)

### Warning: "A single label was found"
- Esto ocurre cuando todas las predicciones son de una sola clase
- Normalmente se resuelve con m√°s √©pocas de entrenamiento

---

## üìö Referencias

- **PyTorch**: https://pytorch.org/
- **Torchvision Models**: https://pytorch.org/vision/stable/models.html
- **Vision Transformer**: https://arxiv.org/abs/2010.11929
- **EfficientNet**: https://arxiv.org/abs/1905.11946

---

## üë§ Autor

Proyecto desarrollado para Tesis de Maestr√≠a en Data Science.

---

## üìÑ Licencia

Este proyecto es parte de una investigaci√≥n acad√©mica.

---

**√öltima actualizaci√≥n**: Diciembre 2024
